\chapter{La piattaforma Neosperience Engage}
\label{capitolo3}
\thispagestyle{empty}

Neosperience è una azienda italiana che offre servizi di marketing e \textit{customer experience}. Customer experience è la percezione che il cliente matura---razionalmente e emotivamente---della relazione con un marchio, un fornitore di beni o servizi. In un mercato globale \mbox{iper-competitivo} e \mbox{iper-connesso}, per contrastare la crescente dispersione degli utenti, il marchio deve stabilire un legame individuale con il cliente. La gestione dell'esperienza cliente \`e la pianificazione e la reazione alle interazioni del cliente al fine di raggiungerne ed eccederne le aspettative ed in questo modo aumentare la soddisfazione, la lealt\`a e il sostegno del cliente al marchio\footnote{``The practice of designing and reacting to customer interactions to meet or exceed customer expectations and, thus, increase customer satisfaction, loyalty and advocacy'' - Gartner}: in una parola, coinvolgimento o \textit{engagement}. L'esperienza cliente digitale apre nuove vie di contatto con il cliente: non solo portali internet, ma applicazioni per social network e dispositivi mobili, tecnologie 3D e negozi virtuali, realtà aumentata, \textit{gamification}. Il ciclo vitale di un cliente rispetto ad un marchio inizia con il coinvolgimento, la scoperta di un prodotto o un servizio; dopo questo primo contatto, seguono diversi \textit{moment of truth}, le occasioni in cui il cliente interagisce con l'azienda e si forma una opinione, consapevole ed inconscia. Il mantenimento del cliente dipende dalla capacit\`a di influire positivamente in ciascuno di questi istanti: la valutazione del prodotto, la decisione dell'acquisto e l'esperienza d'uso. Questo non \`e solo qualit\`a del servizio, ma arrivare ad una comprensione cos\`i profonda del cliente da poter offrire una esperienza---contenuti e benefici---tanto personalizzata ed appagante da indurlo non solo a restare leale al marchio ma a convincere altri ad avvicinarsi. Per raggiungere questo grado di conoscenza \`e necessario estrarre indizi da ogni punto di contatto con il cliente, sfruttando l'immensa mole di informazione nella rete.\\
Recentemente, Neosperience ha sviluppato Engage, una collezione gratuita di librerie per presentare ad un utente il miglior ordinamento degli oggetti di un catalogo, secondo un criterio di pertinenza, basandosi sul profilo dell'utente delineato dalla sua impronta sui social network.
Engage offre una interfaccia (API) o uno strumento di sviluppo (SDK) per arricchire o creare applicazioni per dispositivi mobili. Una applicazione costruita con Engage è una galleria di contenuti; ciascun prodotto del catalogo o \textit{deck} è presentato individualmente su una \textit{card}, un volantino digitale, che racchiude una intestazione, una immagine e una breve descrizione testuale. Attraverso le API Engage è inoltre facilmente possibile offrire funzionalità di \mbox{e-commerce} e condivisione della card su social network. Ad ogni oggetto nella vetrina deve essere infine associato un \textit{target} o utente ideale, colui che l'autore dei contenuti ritiene essere più interessato all'oggetto o propenso ad acquistarlo. Il \textit{target} è definito mediante variabili demografiche---età, genere, luogo di nascita, educazione---, interessi, avversioni e geolocazione---la distanza dell'utente da un luogo specificato. Quando l'utente installa e avvia l'applicazione può connettere i propri profili sui principali social network---Facebook Twitter e Foursquare---permettendo alla piattaforma Engage sottostante di tratteggiare un profilo dell'utente avvalendosi dei dati personali, dei \textit{like} e \textit{hashtag} sia dell'utente sia degli amici sul social network. Partendo da questo profilo, Engage misura per ogni oggetto nel catalogo dell'applicazione la somiglianza tra il \textit{target} dell'oggetto e l'utente; gli oggetti sono quindi riordinati e visualizzati dal più appropriato, quello per cui l'utente è massimamente simile al \textit{target}, al più distante.\\
Questo lavoro è stato motivato dall'esigenza di Neosperience di valorizzare i dati degli utenti raccolti tramite la propria piattaforma Engage. Questi dati difatti racchiudono il potenziale per un diverso approccio alla segmentazione della clientela, facendo leva su informazioni variegate, semi-strutturate e non strutturate, ma nuove e complementari rispetto alle tradizionali categorie sociali e geografiche. L'opportunità offerta da questi dati è la conoscenza puntuale degli interessi, delle opinioni, del mood di ciascun cliente, e poter rispondere in tempo reale, limitati soltanto dalla capacità di elaborare e assimilare questa informazione. Tuttavia, complice la giovinezza della piattaforma, la quantità di dati a disposizione di Neosperience si è rivelata molto al di sotto del volume prospettato a regime, sul quale gli algoritmi e le tecniche di data mining avrebbero dovuto essere messe alla prova. Pertanto, il lavoro si è articolato nei seguenti passi:
\begin{itemize}
\item \hyperref[studio_letteratura]{studio della letteratura}
\item \hyperref[raccolta_dati]{raccolta dei dati}
\item \hyperref[selezione_algoritmi]{selezione degli algoritmi}
\item \hyperref[preparazione_dati]{preparazione dei dati}
\item \hyperref[esecuzione_algoritmi]{esecuzione degli algoritmi}
\item \hyperref[analisi_risultati]{analisi dei risultati}
\end{itemize}
\section{Studio della letteratura}
\label{studio_letteratura}
\section{Raccolta dei dati}
\label{raccolta_dati}
Nel progetto originale, il framework è alimentato da tre sorgenti di dati: Facebook, Twitter e Foursquare.
\subsection{Il modello dei dati}
\textbf{Facebook}, con oltre un miliardo di utenti mensili, è il più diffuso e noto social network al mondo. In Facebook, un utente può pubblicare la propria storia personale, interessi, esperienze, foto, lavoro e perfino stati d'animo. D'altronde, il fulcro dei social network è tessere relazioni, e Facebook non fa eccezione: ogni utente può stringere amicizia con altri utenti, condividere con essi contenuti, conversare, giocare, organizzare eventi ed essere informato di ogni cambiamento nella propria rete sociale. In conclusione, Facebook contribuisce la porzione dominante di informazione: il profilo utente, i like, le amicizie. Come riportato in \autoref{fig:modello_dati}, la frazione osservabile del profilo include il nome, che abbiamo rimosso dai dati per irrilevanza e riservatezza, il genere, la data e il luogo di nascita, la città di residenza, l'educazione---scuola superiore, università e formazione specialistica---, lo stato sociale o sentimentale, l'orientamento sessuale. Al pari di ogni altro nodo del grafo sociale di facebook, i like sono identificati univocamente ma anche già organizzati in oltre 200 macrocategorie, talvolta ulteriormente frazionate in sottogruppi: questo ha permesso di ridurre notevolmente la dimensionalità del problema.

\textbf{Twitter} è un social network e una piattaforma di microblogging. Al cuore di Twitter vi sono i \textit{tweet}, brevi messaggi in 140 caratteri che un utente pubblica e la piattaforma notifica a tutti i suoi contatti, chiamati \textit{follower}. Un utente riceve i tweet delle persone che segue sulla propria bacheca o \textit{home timeline}, da cui può rispondere, inserendosi nel flusso di tweet esistente, o ripubblicare (\textit{retweet}), propagando il tweet ai propri follower. Per organizzare tematicamente le conversazioni, i tweet sono spesso etichettati con un \textit{hashtag}, una parola chiave preceduta da un cancelletto, o \textit{hash} in inglese. Questa convenzione nacque spontaneamente tra gli utenti di Twitter e fu raccolta ed integrata nella piattaforma, che oggi pubblica in tempo reale la lista dei \textit{trending topics}, le parole o argomenti di discussione che compaiono più frequentemente negli ultimi tweet.

\textbf{Foursquare} \`e tanto un social network focalizzato sulla posizione dell'utente quanto un gioco, il cui successo è indubitabilmente connesso al dilagare di dispositivi mobili e intelligenti, sempre più comunemente provvisti di una antenna GPS. Foursquare non solo rende pubblico dove l'utente si trova, permettendo di trovarsi fra amici e di incontrare gli altri utenti nella medesima zona, ma invita gli utenti a registrarsi (\textit{check in}) ai luoghi di incontro che visitano---un negozio, un bar, un museo---e attribuisce punti e distintivi (\textit{badges}) per premiare la frequenza con cui vi si accede o la scoperta di nuovi luoghi prima dei propri amici. Ad esempio, l'utente che ha avuto il maggior numero di check-in in un dato luogo nell'arco di 60 giorni ne viene incoronato \textit{mayor}, letteralmente sindaco, ma deve successivamente difendere il titolo dagli altri utenti.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{pictures/modello_dati.pdf}
    \caption{Modello dei dati}
    \label{fig:modello_dati}
\end{figure}
\subsubsection{Problematiche di integrazione fra le sorgenti}
L'obiettivo finale di questa fase è definire un modello unico dei dati, come esposto in \autoref{fig:modello_dati}, per integrare sorgenti eterogenee.\\
Una evidente differenza fra Twitter e Facebook è la natura e lo scopo delle interazioni tra gli utenti. Facebook è solitamente usato per stare in contatto o ritrovare persone che conosciamo realmente o abbiamo frequentato nel passato. In particolare, una volta stretta amicizia il rapporto tra due amici è paritario e simmetrico: possono scambiarsi liberamente messaggi ed ogni contenuto pubblicato da una parte viene notificato all'altra. Al contrario, Twitter è principalmente adoperato per comunicare con altre persone con le quali, pur non frequentandole nella vita reale, condividiamo interessi o argomenti di discussione. Questo legame più superficiale incide sul grado di omofilia nella rete: individui connessi come \textit{friend} saranno in genere più simili di individui connessi come \textit{follower}, tanto più se la relazione non è reciproca. Twitter realizza un modello asimmetrico di relazione, in cui la discrepanza tra il numero di persone che ci seguono e quelle che seguiamo determina la nostra reputazione all'interno della comunità. Nella pratica, l'asimmetria limita i privilegi di colui che segue: ad esempio, il \textit{follower} non può contattare unilateralmente le persone che segue, a meno che non sia stato esplicitamente autorizzato o la relazione sia stata ricambiata. Questa peculiarità ha sensibili implicazioni sul modello dei dati, giacché il grafo degli utenti deve adesso contenere archi orientati.\\
Una ulteriore peculiarità risiede nel confronto tra \textit{like} e \textit{hashtag}. Mentre la relazione tra un utente Facebook e un like è binaria, o l'utente ha espresso il proprio gradimento di un oggetto o non lo ha fatto, nel caso di Twitter un utente può non adoperare mai un hashtag o usarlo con frequenza. Anche in questo caso il modello dei dati richiede una estensione, tramite l'introduzione di pesi sugli archi utente-hashtag. A differenza del caso precedente, dove un arco non orientato può essere equivalentemente modellato da una coppia di archi orientati, conciliare gli archi privi di peso di Facebook con quelli pesati di Twitter richiede una normalizzazione arbitraria dei pesi. In aggiunta, il significato di un hashtag è tutt'altro che analogo ad un like, poiché, avendo fissato l'argomento, un tweet può esprimere tanto apprezzamento quanto avversione, discussione o ``inutile chiacchiera''\footnote{\url{http://web.archive.org/web/20110715062407/www.pearanalytics.com/blog/wp-content/uploads/2010/05/Twitter-Study-August-2009.pdf}}. Per amalgamare semanticamente i tweet ai like sarebbe necessario discriminare i tweet in semplici categorie, \textit{like} e \textit{dislike}, che tuttavia è un problema di elaborazione del linguaggio naturale e clustering in sé. Infine, la vita media di un hashtag è di gran lunga più breve rispetto ad un like. In termini assoluti, mentre un like è sostenuto da un contenuto---una pagina o una realtà esterna a Facebook---ed esprimendo il like l'utente si connette a tale contenuto nel grafo sociale, la creazione di un hashtag richiede al più uno sforzo di immaginazione; la controparte della proliferazione di hashtag è proprio la loro volatilità. In termini relativi, il carattere episodico e conversevole del tweet richiede tempi di elaborazione ed azione più stringenti, in quanto l'associazione e il coinvolgimento dell'utente rispetto ad un hashtag può rapidamente consumarsi. In sintesi, l'analisi dei tweet richiede algoritmi tolleranti di una elevatissima dimensionalità, coerente con l'elaborazione del linguaggio naturale, possibilmente basati su grafi e che garantiscano una bassa complessità temporale, anche a scapito della qualità.\\
Nel 2010 Facebook lanciò Luoghi, un nuovo componente dell'applicazione ed un clone di Foursquare, di cui imitava la terminologia e le funzionalità. Il servizio conobbe poco successo e fu abbandonato un anno dopo, mantenendo unicamente la possibilità di comunicare la propria posizione quando si pubblica un post. Per questa ragione, Foursquare è un servizio unico nel suo genere e, contribuendo informazione nuova e non ridondante, non richiede sforzi addizionali di assimilazione nel modello.\\
Una volta definiti i criteri di integrazione, l'ultimo passo sarebbe la \textit{entity resolution}, ovvero l'identificazione dei profili che, benché apparentemente scorrelati e provenienti da sorgenti diverse, pertengono al medesimo individuo reale. Questa fase non risulta tuttavia applicabile ai dati a nostra disposizione, che provengono unicamente da Facebook.\\
\subsection{La costruzione del dataset}
\mbox{\textit{Graph API}}\footnote{\url{https://developers.facebook.com/docs/graph-api}} è lo strumento primario per leggere e scrivere sul grafo sociale di Facebook. L'interfaccia offre una rappresentazione della enorme base dati Facebook sotto forma di grafo, composto da:
\begin{description}
\item[nodi]  basilarmente ogni entità: un utente, una foto, una pagina, un commento
\item[archi] le connessioni tra entità, ad esempio la foto inserita in una pagina o il commento allegato alla foto
\item[campi] informazioni sulle entità, come il compleanno di un utente o il titolo di una pagina
\end{description}
(In questa parte Nicola è certamente più ferrato. Da completare)\\
\section{Selezione degli algoritmi}
\label{selezione_algoritmi}
In considerazione della varietà dei dataset su cui avremmo operato, abbiamo selezionato una vasta gamma di algoritmi, cercando di differenziarli per modello dei dati, tecnica di clustering (\ref{sec:classificazione_algoritmi}), approccio alla dimensionalità (\ref{subsec:subspace_clustering}), prestazioni.\\
Limitatamente al modello dei dati, gli algoritmi possono essere raggruppati in tre categorie:
\begin{itemize}
\item clustering su attributi: NetClus \cite{netclus}, MOC \cite{moc}, LAC \cite{lac}, ORCLUS \cite{orclus}
\item clustering su grafo: Blondel et al. \cite{blondel2008fuc}
\item clustering su attributi e grafo: LatentNet \cite{handcock07}, CESNA \cite{cesna}, Inc-Cluster \cite{inc_cluster}, DB-CSC \cite{db_csc}, BAGC \cite{bagc}
\end{itemize}
\subsection{Descrizione degli algoritmi}
\begin{description}
\item[NetClus] è un algoritmo per il clustering di reti composte da entità eterogenee e conformazione a stella (\textit{star network schema}). In assenza di connessioni tra utenti, il modello dei dati descritto in \autoref{fig:modello_dati} riflette esattamente questo scenario: al centro della stella vi è l'utente, da cui scaturiscono archi verso gli attributi di profilo, like, hashtag e check-in, ognuno dei quali forma un nuovo tipo di entità. Il pregio di NetClus è che non si limita ad attribuire una etichetta di cluster a ciascun utente, ma produce un ordinamento dei valori di ciascuna entità in ognuno dei cluster ottenuti, semplificando grandemente l'interpretazione dei risultati.
%Ad esempio, per ogni cluster sarebbero evidenziati i valori di età, luogo di nascita, grado di istruzione, like, check-in\dots più rappresentativi per la popolazione raccolta nel cluster.
In secondo luogo, l'approccio di NetClus riduce fortemente la dimensionalità del problema rispetto agli altri algoritmi su attributi, dove ogni nuovo like o hashtag aggiunge una dimensione al dataset. Un ultimo punto di forza è che non richiede la definizione di una misura di similarità, ma costruisce un modello probabilistico generativo sotto l'ipotesi che la rete esibisca assortatività e \textit{preferential attachment}, come nel caso delle reti sociali. Dato il numero di cluster, l'idea generale di NetClus si compone dei seguenti passi: generare una partizione iniziale degli oggetti ed indurre i \textit{net-cluster} $\{C_{k}^{0}\}_{k=1}^{K}$ dalla rete originale sulla base di queste partizioni; costruire, per ciascun net-cluster, un modello probabilistico generativo $\{P(x|C_{k}^{t})\}_{k=1}^{K}$; quindi calcolare la probabilità a posteriori $P(C_{k}^{t}|x)$ per ciascun oggetto e ricalcolare l'assegnamento degli oggetti ai cluster. I due passi precedenti sono reiterati finché i cluster non raggiungono una condizione stazionaria. Al termine, dalla probabilità a posteriori si ottiene un ordinamento degli oggetti all'interno dei cluster di appartenenza. L'algoritmo ha complessità lineare nel numero di archi, ovvero per reti sparse è approssimativamente lineare nel numero di nodi.
\item[MOC] è un algoritmo probabilistico generativo per l'identificazione di cluster non disgiunti o \textit{overlapping}. L'algoritmo generalizza e semplifica un precedente studio sul clustering sovrapposto di espressioni genetiche \cite{SegalBK03}; con una scelta oculata del modello di probabilità e definizione di distanza---la famiglia esponenziale e la divergenza di Bregman rispettivamente---gli autori sostengono di poter applicare la tecnica a dati sparsi e con numerose dimensioni, laddove il modello gaussiano e la distanza euclidea, usati più comunemente, sono noti offrire scarsi risultati. A testimonianza della formulazione originale, i dati o matrice di espressione $X$ sono modellati come la manifestazione di due fattori, l'appartenenza $M$ e l'attivazione $A$. L'appartenenza descrive quanto i cluster nascosti nei dati si manifestano in ciascun individuo; dato che il modello è \textit{overlapping}, ogni individuo può appartenere simultaneamente a più cluster. L'attivazione indica il peso di ciascuna dimensione dei dati in ognuno dei cluster, ossia quali caratteristiche di un individuo sono determinate più significativamente dall'appartenenza al cluster. I dati sono quindi ricostruiti come il prodotto $X'=M \times A$ tra la matrice di appartenenza e la matrice di attivazione. Seguendo questa intuizione, l'algoritmo costruisce una stima iterativa di $M$ e $A$. Il vettore di appartenenza $M_i$ di ciascun individuo è ottenuto con un approccio \textit{greedy}, volto a minimizzare la distanza tra l'individuo e la sua approssimazione $M_i \times A$: fissata la matrice di attivazione $A$, MOC `accende' con ogni iterazione un nuovo cluster, fino a quando per nessuna scelta è possibile ridurre ulteriormente la funzione obiettivo. La complessità temporale di questa fase è $O(k^3)$ nel numero di cluster $k$. La matrice di attivazione può essere costruita dalla minimizzazione della medesima funzione obiettivo, fissata $M$; seppure sia definita una diversa formula per ogni modello nella famiglia esponenziale e relativa divergenza, la complessità temporale di questa fase può essere stimata in $O(d^3)$.
\item[LAC] è un algoritmo \textit{centroid-based} di \textit{subspace clustering}. Come discusso in \ref{subsec:metodi_partitivi}, le prestazioni degli algoritmi basati sulla distanza euclidea degradano rapidamente al crescere del numero di dimensioni. Per ovviare a questo noto limite, LAC trasforma lo spazio in cui ciascun cluster è immerso: associa ad ogni cluster un vettore di pesi affinché maggiore importanza sia conferita alle dimensioni lungo le quali c'è aggregazione dei punti, all'interno del cluster. I pesi indicano quindi il grado di partecipazione di ciascun attributo al cluster; se i punti sono fortemente raggruppati rispetto a quell'attributo, il peso sarà alto, e basso altrimenti. I pesi sono appresi iterativamente, dalla ottimizzazione della somma degli errori quadrati (SSE), ovvero le distanze, per ciascun cluster, tra il centroide di riferimento e di tutti i punti appartenenti. In assenza di contromisure, tutto il peso sarebbe concentrato sulla dimensione a minima varianza e l'algoritmo scoprirebbe unicamente cluster monodimensionali; per controllare la dimensione dello sottospazio in cui i cluster sono valutati, un termine di penalità controllato dall'utente è inserito nella funzione obiettivo. Sebbene l'esistenza di parametri astratti sia un aspetto in genere indesiderabile, gli autori hanno definito una metodologia \textit{ensemble} per la determinazione del valore ottimo attraverso esecuzioni multiple della procedura di clustering.
\item[ORCLUS] è un algoritmo di clustering proiettato (\textit{projected clustering}) basato su \textit{K}-medoids. Dati due parametri specificati dall'utente, il numero di cluster e il numero di dimensioni dei cluster, ORCLUS identifica un insieme di cluster arbitrariamente allineati---non solo paralleli agli assi, ma ottenuti dalla combinazione lineare delle dimensioni originali---ciascuno in un sottospazio della dimensione specificata. ORCLUS è molto simile all'algoritmo k-means, tranne per il fatto che, invece di misurare le distanze nello spazio completo, queste sono calcolate nei sottospazi di ciascun cluster. Preliminarmente, ORCLUS sceglie casualmente dei `semi' o potenziali medoidi. L'algoritmo richiede quindi un processo iterativo: in ogni iterazione ciascun cluster è progressivamente raffinato, rimuovendo le dimensioni prive di aggregazione e riducendo il numero di cluster dall'accorpamento di quelli più simili. I sottospazi sono formati tramite PCA, ovvero calcolando la matrice di covarianza per ciascun cluster e selezionando gli autovettori con la minore diffusione nel sottospazio del cluster, ovvero quelli associati agli autovalori più piccoli. Quando due cluster sono vicini e hanno simili direzioni degli autovettori sono fusi assieme. A chiusura di ogni iterazione è eseguita la fase di assegnamento: ogni punto è associato al seme più vicino e i semi sono ricalcolati come i centroidi dei cluster appena formati. L'algoritmo è computazionalmente intensivo $O(d^3)$ nella dimensione dei dati, in conseguenza del calcolo della matrice di covarianza e degli autovettori di ciascun cluster. Oltretutto, richiede la specificazione non solo del numero di cluster ma anche della dimensione del sottospazio in cui ciascun cluster è costruito, un parametro difficile da stimare correttamente a priori.
\item[LatentNet] è un algoritmo di clustering probabilistico, basato su un modello generativo. Partendo da un grafo di relazioni binarie, il modello assume che ogni nodo possieda una posizione non osservabile in uno spazio sociale \mbox{\textit{d}-dimensionale}, euclideo e latente. Con questa premessa, la presenza o l'assenza di una connessione tra due individui è indipendente da ogni altra informazione, se sono note le posizioni dei due individui nello spazio sociale. Questo modello esprime in maniera innata tanto la transitività quanto l'omofilia negli attributi osservati. Per introdurre la proprietà di clustering, si assume che le posizioni nello spazio latente siano estratte da un modello misto (\textit{mixture model}) di distribuzioni Gaussiane multivariate: ogni distribuzione è caratterizzata da una propria media e varianza, e rappresenta un diverso gruppo di individui o cluster. Per la stima delle posizioni nello spazio latente, gli autori propongono due metodi. Il primo è un metodo in due fasi: inizialmente calcola la stima a massima verosimiglianza del modello dello spazio latente---che spiega la transitività e l'omofilia---e determina le posizioni degli attori nello spazio sociale; la seconda fase stima i parametri del modello misto, basandosi sulle posizione nello spazio latente ottenute nella prima fase. Il secondo metodo è pienamente Bayesiano e usa \textit{MCMC sampling}: il vantaggio è che stima simultaneamente le posizioni latenti e il modello di clustering, ma è computazionalmente più esigente.
\end{description}
\section{Preparazione dei dati}
\label{preparazione_dati}
\subsection{Rimozione degli outlier}
Per identificare e rimuovere gli outlier abbiamo fatto ricorso al package \textit{outliers} di R.
\subsection{Imputazione dei missing values}
Tra gli algoritmi che abbiamo selezionato, solo Cesna \cite{cesna} è insensibile ai valori mancanti. Per tutti gli altri è stato necessario produrre una versione completa dei dati. A tal fine abbiamo fatto ricorso a tre soluzioni: rimuovere l'individuo con missing values, rimuovere integralmente l'attributo o inferire il valore laddove assente. La prima soluzione è consigliabile quando l'individuo è così povero di informazione da non produrre alcun beneficio all'analisi: questo è il caso di profili con un rigido livello di riservatezza. La seconda soluzione è necessaria quando l'attributo è mancante per una significativa porzione della popolazione: in questo scenario, rimuovere gli individui privi dell'attributo sarebbe un spreco di informazione e non è disponibile sufficiente informazione reale per inferire i valori mancanti. In ultimo, i valori possono essere dedotti tramite imputazione.\\
Dai risultati in \autoref{table:missing_values} si evince che gli attributi \textit{orientamento sessuale} e \textit{stato sentimentale} sono specificati da una estrema minoranza di utenti, certamente troppo pochi per applicare una procedura di imputazione; pertanto sono stati rimossi dal dataset.
\begin{table}[h]
\resizebox{0.9\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{| c | c | c | c | c | c | c |}
\multicolumn{1}{c}{genere}
 &  \multicolumn{1}{c}{età}
 & \multicolumn{1}{c}{\specialcell[t]{luogo di\\nascita}}
 & \multicolumn{1}{c}{\specialcell[t]{luogo di\\residenza}}
 & \multicolumn{1}{c}{educazione}
 & \multicolumn{1}{c}{\specialcell[t]{orientamento\\sessuale}}
 & \multicolumn{1}{c}{\specialcell[t]{stato\\sentimentale}}
 \tabularnewline
\hline
0.0078 & 0.3253 & 0.2802 & 0.2364 & 0.2429 & 0.9913 & 0.9984 \tabularnewline
\hline
\end{tabular}
\caption{Distribuzione dei valori mancanti per attributo}
\label{table:missing_values}
\end{minipage} }
\end{table}
Un discorso a parte merita l'educazione, che descrive l'aver frequentato la scuola superiore, un corso universitario triennale e magistrale. Nonostante si tratti di campi opzionali---un individuo può certamente non aver frequentato l'università---data l'origine dei dati, principalmente studenti universitari e la loro cerchia di  amici, risultano inspiegate percentuali tanto alte (\autoref{table:missing_values}) di assenza di qualsivoglia livello di istruzione. Questo lascia pensare che vi sia un significativa incidenza di missing values anche per questo attributo, ed un stima per difetto si ottiene dall'incidenza di dati incongruenti: individui che frequentano studi universitari senza aver inserito nel proprio profilo i gradi di istruzione inferiori (incongruente in \autoref{table:missing_values_education}).
\begin{table}[h]
\resizebox{0.9\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{| c | c | c | r}
\multicolumn{1}{c}{scuola superiore}
 &  \multicolumn{1}{c}{università triennale}
 & \multicolumn{1}{c}{università specialistica}
 & \multicolumn{1}{c}{}
 \tabularnewline
\cline{1-3}
0.3232 & 0.4176 & 0.9297 & non specificato \tabularnewline
\cline{1-3}
0.0794 & 0.0120 & 0 & incongruente \tabularnewline
\cline{1-3}
\end{tabular}
\caption{Distribuzione dei valori mancanti per ciascun grado di istruzione}
\label{table:missing_values_education}
\end{minipage} }
\end{table}
\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.47\textwidth}
		\includegraphics[width=\textwidth]{pictures/profile_vs_likes.pdf}
		\caption{dataset completo}
		\label{fig:profile_vs_likes_users}
	\end{subfigure}
	\hfill
    %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    %(or a blank line to force the subfigure onto a new line)
	\begin{subfigure}[b]{0.47\textwidth}
		\includegraphics[width=\textwidth]{pictures/profile_vs_likes_dau.pdf}
		\caption{utenti dell'applicazione facebook}
		\label{fig:profile_vs_likes_daus}
	\end{subfigure}
	\caption{Relazione tra il numero di attributi e like nel profilo utente}
	\label{fig:profile_vs_likes}
\end{figure}\\
Mostriamo in \autoref{fig:profile_vs_likes} la relazione nei dati tra la completezza dei dati biografici e il numero di like nel profilo dell'utente. Si può osservare che esiste una moderata correlazione tra le due grandezze, ossia più povero è il profilo meno like 
%Missingness by attribute
%interested_in 0.9913379
%gender 0.007874636
%hometown 0.280652
%location 0.2375384
%birthday 0.3262855
%relationship_status 0.9983857
%education 0.2437594
%missingness for education
%HS			College		GR Sc		
%0.3231751 	0.4175526 	0.9296795
%True missing
%HS			College		GR Sc
%0.0794157	0.01204819	0
missing values introduced by transformations (coordinates missing after geocoding)
\subsection{Trasformazione numerica dei luoghi}

\subsection{Discretizzazione}

\section{Esecuzione degli algoritmi}
\label{esecuzione_algoritmi}

\section{Analisi dei risultati}
\label{analisi_risultati}