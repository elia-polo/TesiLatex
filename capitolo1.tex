\chapter{Introduzione}
\label{Introduzione}
\thispagestyle{empty}
I servizi informatici che utilizziamo quotidianamente---dalla posta elettronica ai motori di ricerca, dai \textit{social network} ai giochi online---sono sempre più spesso gratuiti e si sostengono grazie alla pubblicità: direttamente, esponendo contenuto promozionale, o indirettamente, dalla valorizzazione delle nostre informazioni personali a fini pubblicitari. Per massimizzare l'efficacia della pubblicità, ossia trasformare l'utente in cliente, è tuttavia essenziale identificare i gusti e gli interessi dell'individuo che si ha di fronte, e proporgli inserzioni personalizzate che rispondano o addirittura anticipino una sua reale esigenza. Nell'era odierna dei Big Data, una moltitudine di nuovi dati su masse di
utenti \`e prontamente accessibile: l'attivit\`a sui siti internet, il profilo sui
social network, le relazioni sociali e il sentiment (le opinioni, i gusti e l'affiliazione a idee, prodotti, marchi, individui).  Ci\`o ha portato a ridefinire l'idea stessa della segmentazione di mercato---la disaggregazione dei clienti in gruppi omogenei per esigenze e comportamento di acquisto---per cui la ripartizione in aree geografiche, demografiche e psicografiche \`e obsoleta o insufficiente. Queste realt\`a, la necessit\`a di profilare gli utenti e il diluvio di informazione grezza che ciascuno di noi divulga su internet, sono fortemente sinergiche, ma richiedono una laboriosa raffinazione per poter essere impiegate nel marketing.\\
La segmentazione di mercato può essere costruita a partire dalle divisioni identificate mediante tecniche di clustering, un processo che organizza una popolazione in gruppi formati da individui affini. Un esperto dovr\`a poi attribuire un significato (profiling) a tali gruppi, comporli per caratterizzare una tipologia di consumatori tramite le variabili usate per il clustering nonché le caratteristiche demografiche, geografiche e comportamentali degli individui, al fine di elaborare una strategia di marketing peculiare per ciascun segmento.\\
Pertanto, per avvalersi dell'informazione proveniente dai social network a fini commerciali, è necessario definire una metodologia per il clustering di grandi volumi di dati: profili utente con un elevato numero di attributi e talvolta arricchiti da una tela di relazioni sociali. Lo scopo della tesi è realizzare un framework per il clustering di vasti grafi con attributi, che sia di supporto al processo di segmentazione.\\
Questo lavoro è stato motivato dall'esigenza di Neosperience, una azienda che offre servizi di marketing e \textit{customer experience}, di valorizzare i dati degli utenti---sotto forma di profili Facebook, Twitter e Foursquare---raccolti tramite la propria piattaforma Engage. Il lavoro è iniziato dall'analisi degli algoritmi esistenti in letteratura che potessero adattarsi al tipo, dimensione e volume dei dati su cui avremmo operato. In seguito sono stati raccolti i dati, una ampia collezione di profili Facebook, composti da informazioni di profilo, preferenze (\textit{like}) e connessioni sociali (\textit{friend}). Una volta reperito il codice degli algoritmi, i dati sono stati ripuliti e preparati per le tecniche di clustering selezionate. Dall'esecuzione degli algoritmi su svariati campioni del dataset completo abbiamo potuto evidenziare i punti di forza e debolezza di ciascun approccio. Tramite la misurazione di indici di qualità, siamo in grado di suggerire qual è la miglior parametrizzazione di ciascun algoritmo su un dataset in input e di svolgere una analisi comparativa sulle prestazioni delle diverse tecniche.

\section{Contesto e obiettivi del lavoro}
Il clustering è un processo che, partendo da una definizione di similarità e una popolazione, produce una suddivisione degli individui in gruppi o \textit{cluster}, al fine di massimizzare la similarità intra-cluster, ovvero l'omogeneità degli elementi raggruppati insieme, e la dissimilarità inter-cluster, ossia accentuare le differenze tra gruppi diversi. Si tratta di un procedimento \textit{data-driven}, inevitabilmente determinato dai dati e dalle esigenze del committente; \textit{clustering is in the eye of the beholder}, e non ha pertanto senso dettare quale algoritmo e scelta dei parametri siano sistematicamente ottimali. Nel caso in esame, tuttavia, la struttura dei dati è stabile e ciò permette di avanzare delle linee guida per selezionare preliminarmente un ventaglio di approcci di maggior successo.\\
Negli ultimi anni, lo sviluppo delle capacità di memorizzazione ed elaborazione dei dati, unitamente alla diffusione pervasiva di Internet, hanno prodotto una svolta nell'era digitale, nella quantità e qualità di informazione nascosta nei dati che una tecnica di clustering potrebbe svelare. Questa rivoluzione ha preso il nome di \textit{Big Data}. Big data indica la disponibilità di enormi masse di dati, strutturati e non strutturati: una miniera di informazione grezza che richiede tecniche innovative di elaborazione per capire profondamente la realtà in cui si opera e prendere decisioni migliori\footnote{``Big data is high volume, high velocity, and/or high variety information assets that demand cost-effective, innovative forms of information processing to enable enhanced decision making, insight discovery and process optimization'' - Gartner \cite{laney01}}.
Il paradigma dei Big Data è articolato in tre V: Volume Velocità Varietà.
\begin{description}
\item[Volume]
%Al crescere del volume dei dati, altri fattori oltre alla qualità del risultato assumono rilievo nella valutazione di un algoritmo: la complessità spaziale e temporale, ovvero quanta memoria e tempo di computazione sono necessari per produrre il clustering finale.
Al crescere del volume dei dati, nella valutazione di un algoritmo assumono rilievo non soltanto la qualità dei suoi risultati, ma anche la complessità spaziale e temporale. Inoltre, quando si parla di volume dei dati non ci si riferisce unicamente alla loro cardinalità, ma anche al numero di proprietà o dimensioni associate ad ogni individuo. L'effetto della \textit{dimensionalità} elevata sul clustering è duplice: da un lato, le dimensioni irrilevanti, quegli attributi rispetto ai quali non c'è aggregazione, costituiscono rumore per gli algoritmi; dall'altro, alcune definizioni di distanza (ad esempio quella euclidea) non riflettono più la reale entità delle differenze tra gli individui \cite{Aggarwal01,Beyer99}.
\item[Velocità e Variabilità] Una rete sociale è un oggetto dinamico, nella struttura e nei contenuti. Ogni giorno si sviluppano nuove connessioni, tanto tra individui---\textit{friend} in Facebook e \textit{follower} in Twitter---quanto verso entità---\textit{like} in Facebook e \textit{checkin} in Foursquare. Anche la velocità con cui la nostra impronta digitale evolve varia a seconda dei singoli dati che consideriamo: se da un lato il luogo o la data di nascita sono permanenti, al contrario le amicizie, le relazioni sentimentali e i gusti sono via via più volubili, e devono essere raccolti ed analizzati prima che diventino obsoleti.
\item[Varietà] I dati si manifestano in innumerevoli forme: pur avendo fissate le sorgenti di informazione---Facebook, Twitter e Foursquare---da esse si ricavano tabelle strutturate, flussi di messaggi ed ogni sorta di contenuto multimediale. La sfida è trovare forme adeguate di organizzazione dei dati e tecniche di analisi capaci di adattarsi alla varietà.
\end{description}
Alcune proprietà notevoli delle reti sociali contribuiscono tuttavia a dominare la variabilità nei dati. In una rete sociale ogni nodo è densamente connesso ai propri vicini, cioè esibisce un intrinseco clustering locale; per esempio, è frequente che i nostri amici siano anche amici tra loro. Inoltre, la distanza media tra una coppia arbitraria di nodi di una rete sociale è sorprendentemente bassa rispetto alla dimensione del grafo\footnote{Una rete è detta \textit{small-world network} se la distanza tra due individui scelti a caso è proporzionale a $log N$, dove $N$ è il numero di nodi}; questa proprietà è nota come \textit{teoria del mondo piccolo}. In ultimo, la somiglianza genera connessioni; questo principio, l'\textit{omofilia}, spiega perché siamo spesso simili ai nostri amici, per età, esperienze passate e passioni. In conclusione, la varietà dei dati provenienti da reti sociali non è libera, ma esibisce delle regolarità, specialmente nella cerchia ristretta di ciascun individuo.\\
Prima di poter essere sottoposti al clustering, i dati grezzi devono tuttavia essere elaborati per elevarne la qualità. Questa fase preparatoria, detta \textit{preprocessing}, si sostanzia dei seguenti passi: pulizia, integrazione, riduzione e trasformazione dei dati. La pulizia dei dati ha lo scopo di identificare le incongruenze, rimpiazzare i dati mancanti, attenuare il rumore e rimuovere le anomalie. Dall'integrazione, le differenti sorgenti di dati confluiscono in un unico archivio, avendo cura di definire un formato unico, coerente e privo di ridondanza verso il quale convertire le sorgenti. Alla luce del modello dei dati è possibile tratteggiare le caratteristiche dell'algoritmo di clustering ideale, che farà da guida nella analisi della letteratura e nella selezione delle metodologie esistenti. Tuttavia, tecniche diverse richiedono spesso una apposita formulazione dei dati per offrire i migliori risultati. La riduzione consiste nel comprimere la forma dei dati, in particolare il numero di attributi o il numero di individui, cercando di preservarne intatta la sostanza, l'informazione nascosta. In ultimo si esegue la trasformazione, che agisce sulla scala, sul tipo e sulla granularità dei dati.\\
Nella ricerca della tecnica di clustering più appropriata, oltre ai requisiti imposti dai dati, una caratteristica desiderabile per un algoritmo applicato alle reti sociali è la capacità di individuare comunità parzialmente sovrapposte o addirittura annidate, nonché identificare cluster omogenei per diversi sottoinsiemi di attributi (\textit{subspace clustering}). Infine, l'algoritmo dovrebbe essere scalabile nelle dimensioni e nella cardinalità dei dati.
%Il nostro studio non ha individuato una metodologia che rispondesse simultaneamente a tutte queste esigenze, pertanto abbiamo selezionato un ampio ventaglio di candidati con caratteristiche diverse e che almeno in parte soddisfacessero il profilo ideale che abbiamo delineato. Questa eterogeneità rende difficile confrontare algoritmi di diversa natura, né lo scopo del lavoro è stilare una inverosimile classifica. Piuttosto, l'obiettivo è selezionare le tecniche che possono produrre un risultato di rilievo, definire degli indici che aiutino l'analista dei dati a separare i clustering soddisfacenti da quelli insignificanti, offrire delle procedure per unificare diversi clustering potenziali \cite{Strehl03}.\\

\section{Struttura della tesi}
La tesi è strutturata nel modo seguente.\\
Nel \autoref{capitolo2} analizzeremo la letteratura accademica sul clustering, con un particolare accento sul problema della dimensionalità. Inoltre, discuteremo la problematica della pulizia dei dati e della valutazione dei dataset e dei risultati del clustering.\\
Nel \autoref{capitolo3} descriveremo il framework Engage di Neosperience, per il quale questo lavoro è stato svolto.\\
Nel \autoref{capitolo4} presentiamo la nostra soluzione, dalla raccolta dei dati fino alla esecuzione degli algoritmi.\\
Nel \autoref{capitolo5} discutiamo la procedura ed i risultati dell'analisi sperimentale.\\
Nel \autoref{capitolo6} esponiamo le conclusioni e i possibili sviluppi del lavoro.\\