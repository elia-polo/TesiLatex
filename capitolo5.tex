\chapter{Conclusioni e sviluppi futuri}
\label{capitolo5}
\thispagestyle{empty}
%In quest'ultimo capitolo sintetizzeremo brevemente quanto è stato svolto nella tesi delineando le possibili prospettive future del lavoro, dall'integrazione di sorgenti di dati multiple (Facebook, Twitter e Foursquare) all'aggiunta di nuove funzionalità utili al processo di segmentazione e al marketing in generale.

\section{Conclusioni}
Questo lavoro è stato motivato dall'esigenza di Neosperience---una azienda che offre servizi di marketing e \textit{customer experience}---di avere uno strumento per poter valorizzare i dati degli utenti raccolti tramite la piattaforma Engage: in particolare, l'obiettivo principale è quello di fornire delle tecniche di data preprocessing e degli algoritmi di clustering che siano di supporto alla segmentazione di mercato. La segmentazione di mercato è definita come quel processo che permette di partizionare un ampio insieme di clienti in piccoli gruppi (o \textit{segmenti}) caratterizzati da bisogni omogenei e simili comportamenti di acquisto. L'avvento dei Big Data è stato rivoluzionario in questo campo e ha modificato in maniera sostanziale l'approccio alla segmentazione di mercato. Se prima i dati di ogni consumatore erano difficilmente reperibili e comunque caratterizzati da un basso numero di attributi socio-demografici, con il paradigma dei Big Data si assiste a due fenomeni fondamentali: da un lato, è molto più semplice individuare i propri clienti grazie alla pervasività dei social network; dall'altro, ogni cliente è descritto da un elevato numero di attributi, come ad esempio i dati di profilo della propria pagina Facebook. Questa esplosione di informazioni rende più appetibile e potenzialmente più proficuo il processo di segmentazione, ma aggiunge, d'altro canto, un ulteriore livello di difficoltà. Gestire un grande insieme di clienti e individuare informazioni nascoste al suo interno diventa davvero difficoltoso senza l'ausilio di un procedimento automatico. È proprio a questo punto che la cluster analysis interviene a favore della segmentazione di mercato, fornendo una serie di strumenti che agevolano l'identificazione di caratteri emergenti dalla base di dati aziendale.\\
Purtroppo, complice la giovinezza della piattaforma Engage, non abbiamo potuto disporre dei profili utente su cui condurre tutti gli esperimenti necessari per svolgere il nostro lavoro. Il primo passo è stato, quindi, la creazione di una applicazione per la raccolta dei dati: abbiamo recuperato circa 25 mila profili Facebook, completi di numerose informazioni (anonimizzate) come l'età, il genere, l'istruzione, gli interessi personali (le pagine su cui si è indicato \textit{like}) e relazioni di amicizia, creando un'unica rete sociale con attributi da cui sono partite le analisi e gli sviluppi principali del lavoro. Il passo successivo è stato quello di progettare e mettere a punto una infrastruttura per il preprocessing dei dati tramite procedure consolidate e di nuova generazione che tenessero conto delle peculiarità delle reti sociali: con questi strumenti il grafo iniziale è stato pulito, trasformato e infine campionato in un insieme di sottografi con caratteristiche topologiche e di profilo molto variegate: in questa maniera, abbiamo potuto disporre di una serie di dataset su cui valutare, nel modo più oggettivo possibile, le varie tecniche di clustering. \\
Dopo un approfondito studio della letteratura, abbiamo selezionato un insieme di algoritmi progettando un'interfaccia di trasformazione tra i sottografi a disposizione e il formato in input di ogni algoritmo: in questo modo è stato possibile condurre dei test pratici che misurassero le prestazioni delle varie tecniche di clustering, individuando quelle più promettenti e isolando quelle insoddisfacenti. Per tale scopo sono stati valutati molteplici indici di qualità ed i tempi d'esecuzione al variare dei parametri di ciascuna tecnica. In base a queste analisi abbiamo trovato metodi efficaci per il clustering di dataset medio-piccoli, altri computazionalmente più onerosi ma validi per il subspace clustering di grandi volumi di dati, nonché algoritmi su grafi che sfruttano e ottimizzano simultaneamente le relazioni e la somiglianza tra gli individui, gestendo nativamente i valori mancanti e la dimensionalità del problema. Infine, poiché ogni algoritmo richiede in ingresso almeno la specificazione del numero di cluster da individuare, abbiamo proposto delle soluzioni per la regolazione automatica dei parametri in input, delineando inoltre una serie di suggerimenti sugli scenari di successo e fallimento delle procedure a nostra disposizione. \\ 	

\section{Sviluppi futuri}
La naturale continuazione di questo lavoro può partire dalla soluzione di varie problematiche legate ai dati. Come già affermato nel Capitolo 3, la piattaforma Engage è alimentata da tre sorgenti di dati: Facebook, Twitter e Foursquare. In questa tesi abbiamo lavorato con i profili Facebook perché l'informazione strutturata presente in essi ci ha permesso di focalizzare l'attenzione su aspetti più generali e specifici della cluster analysis. Integrare servizi come Twitter comporta, infatti, altrettante sfide: in questo contesto, il \textit{tweet} è l'informazione principale da analizzare e il suo carattere non strutturato impone l'utilizzo di sofisticate tecniche di elaborazione del linguaggio naturale per estrarre la semantica ad essi associata ed individuare gli interessi dell'utente. Un ulteriore obiettivo da raggiungere sarebbe quello dell'\textit{entity resolution}, ovvero l'identificazione e l'unificazione dei profili Facebook, Twitter e Foursquare che appartengono al medesimo individuo. Oltre alle difficoltà implementative di questa proposta ne incorrerebbero immediatamente altre teoriche, come l'esplosione della dimensionalità dei dati e la formulazione di un modello coerente che tenga conto delle diversità concettuali dei tre Social Network (si veda la \autoref{section_modello_dati}).\\

Un'altra prospettiva attraente riguarda l'automatizzazione della scelta dell'algoritmo: ci siamo chiesti, infatti, in che misura è possibile suggerire una tecnica di clustering su un certo dataset in ingresso, basandosi solamente sulle esecuzioni e le analisi fatte precedentemente, senza applicare tutti gli algoritmi a disposizione. Questo è un obiettivo tanto entusiasmante quanto delicato, infatti comporta una minuziosa attenzione a due questioni importanti: in primo luogo, come abbiamo sempre specificato nel corso del presente lavoro, un clustering è significativo solo se convalidato e, semmai, trasformato dal cliente; ciò comporta che se il framework suggerisce automaticamente l'utilizzo di un algoritmo con una certa parametrizzazione non vuol dire che il risultato sia da accettare in maniera \virgolette{dogmatica}. In secondo luogo, a complicare le cose, intervengono numerose sfide teoriche ed implementative. Se per il suggerimento di un algoritmo ci si vuole basare solamente sulle analisi fatte in precedenza, allora bisogna in qualche modo definire una misura di similarità tra insiemi di individui, per associare al dataset in esame  il più simile dataset già processato e proporre per il primo le stesse considerazioni fatte sull'ultimo. Questo è un compito assai complicato sotto molteplici punti di vista. Sicuramente, per produrre risultati significativi è necessario aver memorizzato svariate analisi condotte su dataset altrettanto numerosi e il più possibile variegati dal punto di vista topologico e degli attributi di profilo. Conclusa questa fase resta comunque il problema della progettazione delle funzioni di similarità tra dataset: come abbiamo affermato nei capitoli precedenti, il nostro lavoro mette  a disposizione un modulo per il calcolo di metriche topologiche che possono essere utilizzate per etichettare un grafo in ingresso e calcolare quanto esso si differenzi da quelli già processati. Però, per raggiungere a pieno l'obiettivo è necessario stabilire anche in quale misura due dataset sono simili relativamente agli attributi e individuare, in definitiva, una funzione univoca che tenga conto contemporaneamente delle caratteristiche topologiche e di profilo dei dati in ingresso.\\

Sempre nell'ambito del marketing e delle dinamiche \textit{social} potrebbe essere molto interessante arricchire il nostro lavoro con strumenti di \textit{sentiment analysis} che svolgono oramai un ruolo di fondamentale importanza per recuperare automaticamente le opinioni dei clienti riguardo un prodotto o servizio. Utilizzando queste tecniche è possibile condurre una ulteriore segmentazione di mercato mirata ad intercettare il \textit{mood} dei consumatori e intervenire a seconda della positività o negatività delle opinioni e del relativo grado di intensità emotiva. Questi aspetti possono avere ancor più valore del singolo \textit{like} sulla pagina Facebook aziendale, e rappresentano per tanto una nuova frontiera per il monitoraggio della reputazione del brand e la pianificazione di innovative strategie di marketing.\\

In ultimo, citiamo una idea stimolante riguardo il \textit{viral marketing} che può essere facilmente integrata nel nostro progetto. Supponiamo che una azienda stia cercando di promuovere un prodotto all'interno di una popolazione di potenziali clienti tramite l'offerta di campioni di prova gratuiti: è fondamentale chiedersi a chi proporre questa offerta. Gli studi sul \textit{marketing virale} \cite{WOM} affermano che c'è un vantaggio molto importante nel far conoscere un certo brand tramite il \textit{passaparola} tra conoscenti: infatti un consumatore è più propenso all'acquisto se è stato consigliato da una persona fidata. Questo meccanismo, inoltre, innesca una cascata di segnalazioni che da un numero basso di utilizzatori iniziali può portare ad un ampio gruppo di clienti finali. Per questa ragione è essenziale individuare, all'interno di un grafo sociale, gli \textit{opinion leader}, ovvero le persone più influenti dalle quali è possibile ottenere l'effetto cascata maggiore e proporre loro l'offerta dei campioni gratuiti \cite{InfluNodes}.